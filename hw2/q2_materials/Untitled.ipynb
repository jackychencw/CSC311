{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Methods for doing logistic regression.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from utils import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_predict(weights, data):\n",
    "    \"\"\"\n",
    "    Compute the probabilities predicted by the logistic classifier.\n",
    "\n",
    "    Note: N is the number of examples and \n",
    "          M is the number of features per example.\n",
    "\n",
    "    Inputs:\n",
    "        weights:    (M+1) x 1 vector of weights, where the last element\n",
    "                    corresponds to the bias (intercepts).\n",
    "        data:       N x M data matrix where each row corresponds \n",
    "                    to one data point.\n",
    "    Outputs:\n",
    "        y:          :N x 1 vector of probabilities. This is the output of the classifier.\n",
    "    \"\"\"\n",
    "\n",
    "    N, M = data.shape[0], data.shape[1]\n",
    "    y = np.zeros((N,1))\n",
    "    new_data=np.hstack((data, np.ones((N,1))))\n",
    "    y = np.dot( new_data, weights)\n",
    "    y = sigmoid(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(targets, y):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics.\n",
    "    Inputs:\n",
    "        targets : N x 1 vector of targets.\n",
    "        y       : N x 1 vector of probabilities.\n",
    "    Outputs:\n",
    "        ce           : (scalar) Cross entropy. CE(p, q) = E_p[-log q]. Here we want to compute CE(targets, y)\n",
    "        frac_correct : (scalar) Fraction of inputs classified correctly.\n",
    "    \"\"\"\n",
    "    ce = - np.sum(np.dot(targets.T, np.log(y)))\n",
    "    correct_prediction = len(zip(*np.where((y > 0.5) & (targets == 1)))) + len(zip(*np.where((y<0.5) & (targets==0))))\n",
    "    frac_correct = float(correct_prediction) / len(targets)\n",
    "    return ce, frac_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic(weights, data, targets, hyperparameters):\n",
    "    \"\"\"\n",
    "    Calculate negative log likelihood and its derivatives with respect to weights.\n",
    "    Also return the predictions.\n",
    "\n",
    "    Note: N is the number of examples and \n",
    "          M is the number of features per example.\n",
    "\n",
    "    Inputs:\n",
    "        weights:    (M+1) x 1 vector of weights, where the last element\n",
    "                    corresponds to bias (intercepts).\n",
    "        data:       N x M data matrix where each row corresponds \n",
    "                    to one data point.\n",
    "        targets:    N x 1 vector of targets class probabilities.\n",
    "        hyperparameters: The hyperparameters dictionary.\n",
    "\n",
    "    Outputs:\n",
    "        f:       The sum of the loss over all data points. This is the objective that we want to minimize.\n",
    "        df:      (M+1) x 1 vector of derivative of f w.r.t. weights.\n",
    "        y:       N x 1 vector of probabilities.\n",
    "    \"\"\"\n",
    "    N, M = data.shape[0], data.shape[1]\n",
    "    y = logistic_predict(weights, data)\n",
    "    f = np.sum(-np.dot(targets.T,np.log(y))) - np.sum(np.dot((1-targets.T), np.log(1 - y)))\n",
    "    new_data = np.hstack((data, np.ones((N,1))))\n",
    "    df = np.dot(new_data.T, (y - targets))\n",
    "    return f, df, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
